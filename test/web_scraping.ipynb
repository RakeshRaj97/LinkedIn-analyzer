{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "\n",
    "from PIL import Image\n",
    "import simplejson as json \n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import requests\n",
    "import time\n",
    "from datetime import date\n",
    "import http.client, urllib.request \n",
    "import urllib.parse, urllib.error \n",
    "import base64, sys \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sign in Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signin(file='config.txt'):\n",
    "\n",
    "    driver.get('https://www.linkedin.com/login')\n",
    "\n",
    "    #Login credentials for Linkedin\n",
    "    file=open(file)\n",
    "    lines=file.readlines()\n",
    "    username=lines[0]\n",
    "    password=lines[1]\n",
    "\n",
    "    # locate username and password form login page by HTML id\n",
    "    enter_username = driver.find_element_by_id('username')\n",
    "    enter_password=driver.find_element_by_id('password')\n",
    "\n",
    "    # send_keys() to simulate key strokes\n",
    "    enter_username.send_keys(username)\n",
    "    enter_password.send_keys(password)\n",
    "\n",
    "    #Submit Credentials\n",
    "    enter_password.submit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scroll Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll():\n",
    "    SCROLL_PAUSE_TIME = 2\n",
    "    \n",
    "    #Scroll to see more and click if visible\n",
    "    \n",
    "    driver.execute_script(\"window.scrollTo(0,560);\")\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    \n",
    "    try:\n",
    "        driver.find_element_by_id('line-clamp-show-more-button').click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #Scroll back to top \n",
    "    \n",
    "    driver.execute_script(\"window.scrollTo(0,0);\")\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    return soup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcitions for Scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_name():\n",
    "    name_all= soup.find('div',{'class':'flex-1 mr5'})#\n",
    "    name=name_all.find('li',{'class':'inline t-24 t-black t-normal break-words'}).get_text().strip()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_image():\n",
    "    imgtag=soup.select('img[title]')\n",
    "    urllib.request.urlretrieve(imgtag[0]['src'],'scraped_image.jpg')\n",
    "    return imgtag[0]['src']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_about():\n",
    "    try:\n",
    "        about_all= soup.find('span',{'class':'lt-line-clamp__raw-line'}).get_text().strip()\n",
    "        return about_all\n",
    "    except:\n",
    "        return 'None'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_header():\n",
    "    name_all= soup.find('div',{'class':'flex-1 mr5'})\n",
    "    header=name_all.find_all('h2')[0].get_text().strip()\n",
    "    return header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_location():\n",
    "    name_all= soup.find('div',{'class':'flex-1 mr5'})\n",
    "    location=name_all.find_all('li')[2].get_text().strip()\n",
    "    return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_connections():\n",
    "    name_all= soup.find('div',{'class':'flex-1 mr5'})\n",
    "    connections=name_all.find_all('li')[3].get_text().strip()\n",
    "    return connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_joining():\n",
    "    company_all= soup.find('div',{'class':'pv-entity__summary-info pv-entity__summary-info--background-section'})\n",
    "    joining=company_all.find_all('span')[2].get_text().strip()\n",
    "    return joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_experience():\n",
    "    company_all= soup.find('div',{'class':'pv-entity__summary-info pv-entity__summary-info--background-section'})\n",
    "    experience=company_all.find_all('span')[4].get_text().strip()\n",
    "    return experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_company():\n",
    "    company_all= soup.find('div',{'class':'pv-entity__summary-info pv-entity__summary-info--background-section'})\n",
    "    company=company_all.find_all('p')[1].get_text().strip().split('\\n')[0]\n",
    "    return company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_title():\n",
    "    company_all= soup.find('div',{'class':'pv-entity__summary-info pv-entity__summary-info--background-section'})\n",
    "    title=company_all.find_all('h3')[0].get_text().strip()\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_college():\n",
    "    college_all= soup.find('div',{'class':'pv-entity__degree-info'})\n",
    "    college=college_all.find_all('h3')[0].get_text().strip()\n",
    "    return college"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_degree():\n",
    "    college_all= soup.find('div',{'class':'pv-entity__degree-info'})\n",
    "    degree=college_all.find_all('span')[1].get_text().strip()\n",
    "    return degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_degree_year():\n",
    "    college_all= soup.find_all('time')\n",
    "    year1=college_all[0].get_text().strip()\n",
    "    year2=college_all[1].get_text().strip()\n",
    "    year=year1 +'-'+ year2\n",
    "    return year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Login to Linkedin and enter profiles to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('Link.csv')\n",
    "\n",
    "dates=[]\n",
    "name=[]\n",
    "image=[]\n",
    "about=[]\n",
    "header=[]\n",
    "location=[]\n",
    "connections=[]\n",
    "joining=[]\n",
    "experience=[]\n",
    "company=[]\n",
    "title=[]\n",
    "college=[]\n",
    "degree=[]\n",
    "degree_year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "signin()\n",
    "for link in df1.URL.values:\n",
    "    Linkedin_url = link\n",
    "    driver.get(Linkedin_url)\n",
    "    soup=scroll()\n",
    "    dates.append(pd.datetime.today().strftime('%d %b, %Y'))\n",
    "    \n",
    "    #Scrapping data and appending it to lists\n",
    "    name.append(Scrape_name())\n",
    "    image.append(Scrape_image())\n",
    "    about.append(Scrape_about())\n",
    "    header.append(Scrape_header())\n",
    "    location.append(Scrape_location())\n",
    "    connections.append(Scrape_connections())\n",
    "    joining.append(Scrape_joining())\n",
    "    experience.append(Scrape_experience())\n",
    "    company.append(Scrape_company())\n",
    "    title.append(Scrape_title())\n",
    "    college.append(Scrape_college())\n",
    "    degree.append(Scrape_degree())\n",
    "    degree_year.append(Scrape_degree_year())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>image</th>\n",
       "      <th>about</th>\n",
       "      <th>header</th>\n",
       "      <th>location</th>\n",
       "      <th>connections</th>\n",
       "      <th>joining</th>\n",
       "      <th>experience</th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>college</th>\n",
       "      <th>degree</th>\n",
       "      <th>degree_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 Aug, 2020</td>\n",
       "      <td>Cody Middlebrook</td>\n",
       "      <td>https://media-exp1.licdn.com/dms/image/C5103AQ...</td>\n",
       "      <td>Most quickly identified by my Filmmaking, doub...</td>\n",
       "      <td>The AI Guy | Reimagining Artificial Intelligen...</td>\n",
       "      <td>Sydney, Australia</td>\n",
       "      <td>500+ connections</td>\n",
       "      <td>Field Of Study</td>\n",
       "      <td>Dates attended or expected graduation</td>\n",
       "      <td>Field Of Study</td>\n",
       "      <td>London Business School</td>\n",
       "      <td>London Business School</td>\n",
       "      <td>Diploma in Computer Programming</td>\n",
       "      <td>1997-2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 Aug, 2020</td>\n",
       "      <td>Shweta Sharma</td>\n",
       "      <td>https://media-exp1.licdn.com/dms/image/C5603AQ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Science Consultant  at Arcadis</td>\n",
       "      <td>Clayton, Victoria, Australia</td>\n",
       "      <td>500+ connections</td>\n",
       "      <td>Nov 2019 – Present</td>\n",
       "      <td>10 mos</td>\n",
       "      <td>Arcadis</td>\n",
       "      <td>Data Science Consultant</td>\n",
       "      <td>Monash University</td>\n",
       "      <td>Master of Data Science</td>\n",
       "      <td>2018-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 Aug, 2020</td>\n",
       "      <td>Rohan Singh</td>\n",
       "      <td>https://media-exp1.licdn.com/dms/image/C5635AQ...</td>\n",
       "      <td>Recently completed Masters of Data Science fro...</td>\n",
       "      <td>Data Scientist Intern at AI Australia</td>\n",
       "      <td>Malvern East, Victoria, Australia</td>\n",
       "      <td>365 connections</td>\n",
       "      <td>Aug 2020 – Present</td>\n",
       "      <td>1 mo</td>\n",
       "      <td>AI Australia</td>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Monash University</td>\n",
       "      <td>Master of Data Science</td>\n",
       "      <td>2018-2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date              name  \\\n",
       "0  10 Aug, 2020  Cody Middlebrook   \n",
       "1  10 Aug, 2020     Shweta Sharma   \n",
       "2  10 Aug, 2020       Rohan Singh   \n",
       "\n",
       "                                               image  \\\n",
       "0  https://media-exp1.licdn.com/dms/image/C5103AQ...   \n",
       "1  https://media-exp1.licdn.com/dms/image/C5603AQ...   \n",
       "2  https://media-exp1.licdn.com/dms/image/C5635AQ...   \n",
       "\n",
       "                                               about  \\\n",
       "0  Most quickly identified by my Filmmaking, doub...   \n",
       "1                                               None   \n",
       "2  Recently completed Masters of Data Science fro...   \n",
       "\n",
       "                                              header  \\\n",
       "0  The AI Guy | Reimagining Artificial Intelligen...   \n",
       "1                Data Science Consultant  at Arcadis   \n",
       "2              Data Scientist Intern at AI Australia   \n",
       "\n",
       "                            location       connections             joining  \\\n",
       "0                  Sydney, Australia  500+ connections      Field Of Study   \n",
       "1       Clayton, Victoria, Australia  500+ connections  Nov 2019 – Present   \n",
       "2  Malvern East, Victoria, Australia   365 connections  Aug 2020 – Present   \n",
       "\n",
       "                              experience         company  \\\n",
       "0  Dates attended or expected graduation  Field Of Study   \n",
       "1                                 10 mos         Arcadis   \n",
       "2                                   1 mo    AI Australia   \n",
       "\n",
       "                     title                 college  \\\n",
       "0   London Business School  London Business School   \n",
       "1  Data Science Consultant       Monash University   \n",
       "2    Data Scientist Intern       Monash University   \n",
       "\n",
       "                            degree degree_year  \n",
       "0  Diploma in Computer Programming   1997-2000  \n",
       "1           Master of Data Science   2018-2020  \n",
       "2           Master of Data Science   2018-2020  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "linkedin = {'date':dates,'name':name,'image':image,'about':about,'header':header,'location':location,'connections':connections,\\\n",
    "            'joining':joining,'experience':experience,'company':company,'title':title,'college':college,'degree':degree,\\\n",
    "            'degree_year':degree_year}  \n",
    "    \n",
    "linkedin_df = pd.DataFrame(linkedin) \n",
    "linkedin_df.to_csv('Linkedin_profiles.csv')\n",
    "linkedin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
